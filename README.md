# GCP Centralized Logging & Visualization Scaffold

This repository contains the infrastructure code, configuration, and application code for a scalable, organization-wide logging solution on Google Cloud Platform, now enhanced with Qdrant vector search and Ollama embeddings for advanced semantic log retrieval.

## Architecture

The solution uses a **Hub-and-Spoke** logging model at the Organization level:
1.  **Ingestion**: All logs (Application, Audit, System) from all Projects in the Org are intercepted by Organization Logging Sinks.
2.  **Storage (Hot/Analytics)**: `org-central-sink-bq` -> BigQuery Dataset (`central_logging_v1`).
    - Used for: Deep analysis, SQL querying, long-term trend analysis.
3.  **Storage (Cold/Compliance)**: `org-central-sink-gcs` -> GCS Bucket (`dacvisuals-central-logs-archive-v1`).
    - Lifecycle: 30 days Standard -> 90 days Coldline -> 365 days Archive.
4.  **Real-Time (Alerting)**: `org-central-sink-alerts` -> Pub/Sub (`logging-critical-alerts`).
    - Used for: Triggering Cloud Functions or external webhooks for `ERROR` and `CRITICAL` logs.
5.  **Vector Search**: Logs embedded via Ollama, stored in Qdrant for semantic/filtered/hybrid queries.
    - Supports chat-based log debugging with tool calling.

## New Features
- **Semantic Log Search**: Vector similarity on log messages.
- **Advanced Querying**: Filters, grouping, hybrid fusion, formula rescoring.
- **Ollama Chat Agent**: Natural language queries via tools.
- **Continuous Optimization**: Benchmark-gated schema/index tuning.

## Directory Structure

```
GCP_LOGGING/
├── src/                 # Unified Cloud Run service (FastAPI): UI + API + agent streaming
│   ├── api/             # FastAPI entrypoint (uvicorn src.api.main:app)
│   ├── glass_pane/      # UI template + canonical BigQuery query builder
│   ├── agent/           # LangGraph-based log debugger agent + continuous optimizer
│   ├── services/        # Qdrant, Ollama, embedding, chat services
│   ├── pipelines/       # Log ingestion pipeline
│   ├── schemas/         # Payload validation schemas
│   └── bench/           # Benchmark harness + tuning recommender
├── app/
│   └── glass-pane/      # Legacy Flask implementation (kept for reference)
├── config/
│   ├── gcs_lifecycle.json # Lifecycle rules for Archive bucket
│   └── ...               # Previous config backups
├── dashboards/
│   └── glass_pane.json   # Cloud Monitoring Dashboard definition
├── docs/                # Architecture, benchmarks, migrations docs
├── tests/               # Unit and integration tests
├── specs/               # Agent specs and configurations
└── scripts/             # Utility scripts for ingestion and agents
├── functions/
│   └── log-processor/    # Cloud Function triggered by Pub/Sub for real-time alerting
├── scripts/
│   └── deploy_scaffold.sh # Master deployment script
└── README.md
```

## Deployment Guide

### 1. Prerequisite
Ensure you are authenticated as an Org Admin:
```bash
gcloud auth login
gcloud config set project diatonic-ai-gcp
```

### 2. Deploy Infrastructure
Run the scaffold script to create Buckets, Datasets, Topics, and Sinks:
```bash
cd scripts
./deploy_scaffold.sh
```
*Note: This script handles IAM binding creation for the unique writer identities generated by the Sinks.*

### 3. Deploy Unified Cloud Run Service (UI + API + Agent)
Build and deploy the unified service to Cloud Run:
```bash
# Builds the root Dockerfile (runs: uvicorn src.api.main:app)
gcloud builds submit --tag gcr.io/diatonic-ai-gcp/glass-pane

gcloud run deploy glass-pane \
  --image gcr.io/diatonic-ai-gcp/glass-pane \
  --platform managed \
  --allow-unauthenticated \
  --set-env-vars PROJECT_ID_LOGS=diatonic-ai-gcp,PROJECT_ID_AGENT=diatonic-ai-gcp,PROJECT_ID_FINOPS=diatonic-ai-gcp,CANONICAL_VIEW=org_observability.logs_canonical_v2
```

### 4. Deploy Dashboard
Import the dashboard configuration:
```bash
gcloud monitoring dashboards create --config-from-file=dashboards/glass_pane.json
```

## Future Roadmap
- **Multi-Cloud**: Use Google Cloud Logging Agent (BindPlane or Fluentd) on AWS/Azure to forward logs to this central BigQuery dataset.
- **On-Prem**: Install Fluentd with the Cloud Logging plugin on on-prem servers.
